+ 操作系统应该在内存方面承担的功能：
	1. 为程序提供地址转换功能
	2. 内存保护：使各个进程在各自内存空间中互不打扰
	3. 内存空间的分配和回收
	4. 从逻辑性上对内存空间进行扩充

## 地址转换
程序从编写到运行的过程：
```mermaid
graph LR;
编辑代码 --编译--> 编译代码:各自相对/逻辑地址 --链接--> 链接装入模块:完成相对/逻辑地址 --装入--> 装入内存:绝对/物理地址
```

+ 编译：
  + 静态链接：先链接再一起放入内存
  + 装入时动态链接：一边链接一边装入内存
  + 运行时动态链接：只有在程序运行时需要的模块才链接并装入内存

+ 装入：
  1. 绝对装入：在编译时就确定最后的绝对的地址，灵活性低，只使用于单道程序环境
  2. 静态重定位/可重定位装入：在装入程序将逻辑地址改为绝对地址，不能再修改
  3. 动态重定位/动态运行时装入：装入内存时不修改相对地址，使用重定位寄存器保存程序起始地址，使用时计算

## 内存保护
> 各进程之间不能互相使用对方内存空间

+ 1. 设置一对上、下限寄存器
+ 2. 采用重定位寄存器（基址寄存器）和界地址寄存器（限长寄存器）

## 内存分配和回收

+ 内部碎片：分配给某进程的内存区域中，如果有些部分没有用上
+ 外部碎片：是指内存中的某些空闲分区由于太小而难以利用
  + 可通过紧凑/拼凑Compaction技术解决外部碎片

### 连续分配

1. 单一连续分配：内存分为系统区和用户区：用户区只能有一个进程使用，实现简单、无外部碎片，可采用覆盖技术扩充，不一定需要内存保护。
2. 固定分区分配：把用户区进一步划分，固定大小，每个分区只有一个作业
   1. 分区相等：缺乏灵活性，适用于控制多个相同作业的场景
   2. 分区不等：增加灵活性：建立链表数据结构抽象一个分区说明表，从小到大分配，标记大小、起始地址、状态（是否被分配）
      + 优点：简单、无外部碎片
      + 缺点：
        1. 当程序太大，无合适分区，只能使用性能低的覆盖技术
        2. 内部碎片（内存空间不是和分区大小完全匹配，多余空间被浪费），内存利用率低
3. 动态分区分配/可变分区分配：不预先划分，装入时计算并建立分区
   + 记录：空闲分区表（同上）或空闲分区链
   + 怎么分配分区：分配算法
   + 怎么回收分区：

#### 分配算法

1. 首次适应算法：每次从低地址开始查找，找到第一个能满足大小的空闲分区  
   空闲分区以地址递增的次序排序，每次分配内存时顺序查找找到大小能满足要求的第一个空闲分区，并修改数据结构
2. 邻近适应算法：为解决首次适应算法的问题，因为它会容易在低地址的部分产生内存碎片，但是每次使用都是也要经过这些，开销大。于是把数据结构组织成循环的，维护一个标记表示上次分配的位置，下次分配从此开始。算法开销小。但是有问题首次适应算法还有这样的优点，都是从头开始，更容易保留高地址的大分区，邻近适应反而失去了这样的优势
3. 最佳适应算法：优先用小的，这样有尽可能大的空闲区  
   实现上按容量递增次序链接，顺序查找
   + 缺点：由于是优先是小的，会更容易留下小的难以利用的内存块，会有很多内存碎片
4. 最大适应算法：和2相反，解决外部碎片，问题变成了把大块分区都用了，如果出现大进程则不能运行
	![](https://cdn.jsdelivr.net/gh/zweix123/CS-notes@master/resource/Operating-System/连续内存分配算法.jpg)
### 离散分配

#### 基本分页存储管理
将内存空间分为若干大小相等的分区，每个分区就是一个**页框/页帧/内存块/物理块**，并从0开始编号，再将用户进程的地址空间也按页框大小分成一个个区域，即**页/页面**，并从0开始编号，即页号。此时内部碎片和页框的大小有关。每个页面放入每个页框（可以不连续）

+ 地址转换：
  1. 逻辑地址对应页号：
     + 页号：逻辑地址`/`页面长度
     + 页内偏移量/页内地址：逻辑地址`%`页面长度
     > 一般会将页面大小设置为2的整数倍，这样上列的计算直接相当于去某个区间的二进制位

  2. 得到页面对应内存的起始地址：
     + 为每个进程建立一个页表：有页号列和块号列组成，表示对应关系
       > 这里的页号是不需要显示存储的，可通过偏移长度和页框大小进行计算所得

     物理地址：页面地址+页内偏移量
+ 实现：基本地址转换实现极值：页表寄存器PTR，存放页表在内存中的起始地址F和页表长度M，存在进程的PCB中运行时放入寄存器
	![](https://cdn.jsdelivr.net/gh/zweix123/CS-notes@master/resource/Operating-System/基本分页地址管理地址转换.jpg)

##### 快表
> 每访问一个逻辑地址，都要查询内存中的页表

+ 具有快表的地址变换机构：
  > 局部性原理：
  >
  > + 时间局部性：指令和数据可能再次访问
  > + 空间局部性：存储单元和周边的可能再次访问

  快表/联想存储器TLB：访问速度比内存块很多的高速缓冲存储器，存储当前访问的若干页表项，对应着内存中的页表常称为慢表
  + 先查快表（快表实现），没有内存（慢表时间），算完放入快表（慢表时间）

##### 二级页表
> 单极页表的问题：
>
> 1. 页表本身的存储空间就很大，而且还要连续
> 2. 由于局部性原理，一段时间只需访问问某几个页面就能正常运行，没必要让整个页面都常驻内存

+ 二级页表：将页表进行分组，使每个内存块可以放一个分组，再为离散的页表建立表**页目标表/外层页表/顶层页表**，这个表里添加一列作为标记位表示是否调入内存

#### 基本分段存储管理
进程的地址空间，按照程序自身的逻辑关系划分为若干个段，每个段都有用户命令的段名，有OS自动为其从0开始编号的段号  
内存分配规则：以段为单位进行分配，每个段在内存中占据连续空间，且不一定相邻  
较于分页的优点：按逻辑功能模块划分，用户控制更方便、程序可读性更好  
段表：表头：段号、段长、基址（起始位置）（和分页相同，段号也是隐式的）
![](https://cdn.jsdelivr.net/gh/zweix123/CS-notes@master/resource/Operating-System/基本分段存储管理地址转换.jpg)

>套娃快表

#### 段页式管理
+ 基本分页存储管理和基本分段存储管理的比较：
	![](https://cdn.jsdelivr.net/gh/zweix123/CS-notes@master/resource/Operating-System/分段分页管理比较.jpg)
  + 分段比分页更容易实现信息的共享和保护：有些功能的代码需要多个进程进行访问（只有纯代码/可重入代码这样不能修改不是临界资源的可以共享，其他的不能共享），由于分段式这部分代码肯定是完整独立的，所以只需指向同一位置即可，但是分区可能这个逻辑功能的代码在多个分区。

    |          | 优点                                             | 缺点                                           |
    | -------- | ------------------------------------------------ | ---------------------------------------------- |
    | 分页管理 | 内存空间利用率高，不会产生外部碎片、少量页内碎片 | 不方便按照逻辑实现信息的共享和保护             |
    | 分段管理 | 与之相反                                         | 如果段过大，不易管理<br>段式管理会产生外部碎片 |

---

对段进行分区，表的表头变成：段号（程序员提供）、页号（OS自动负责）、页内偏移量
![](https://cdn.jsdelivr.net/gh/zweix123/CS-notes@master/resource/Operating-System/段页式地址转换.jpg)

## 虚拟内存
+ 覆盖技术：将程序分为多个段/模块，常用的段常驻内存，不常用的段在需要时调入内存
  + 内存分为固定区和若干覆盖区
    + 固定区常驻内存
    + 覆盖区放入不常用的，一个覆盖区多段程序使用

  要求用户必须在代码中声明覆盖区域，操作系统实现自动覆盖，对用户不透明，增加变成负担

+ 交换/对换技术：内存和外村的交换，不同进程之间独立
  + 换到哪里？硬盘分为文件区和对换区：
    + 文件区是存储空间，要求利用率，是离散的
    + 兑换区，要求速度，是连续分配的
  + 什么时候交换？
  + 换出哪些？

---

+ 传统式管理方式的特点：
  + 一次性：作业必须一次性全部装入内存后才能开始运行
    + 作业大时不是能全部放入，无法运行
    + 大量作业时不能全部放入，并发度降低
  + 驻留性：作业被装入内存就会一直驻留在内存直到运行结束，但其实一段时间只需要一部分程序一部分数据，浪费

+ 虚拟内存的根源就是局部性原理：
  + 高速缓存技术就是这种原理的体现

----

虚拟内存的最大容量：就是CPU的寻址范围  
虚拟内存的实际容量：就是物理的存储内存外存的和寻址范围的最小值  

---

+ 虚拟内存特征：
  1. 多次性：程序分多次调入内存
  2. 对换性
  3. 虚拟性
+ 建立在离散分配/非离散分配的基础上（传统管理是基本分页，虚拟内存是请求分页）
  + 请求分页存储管理
  + 请求分段存储管理
  + 请求段页式存储管理

---

+ 操作系统发挥的作用：
  + 请求调页/段：访问的信息不在内存，需要从外存调入内存
  + 页面/段置换：把暂时用不到的信息换出内存

### 请求分页
+ 页表：  
	字段如下：内存块号（同上）、状态位（表示是否已经调入内存）、访问字段（页面置换算法参数）、修改位（调入内存后是否被修改过）、外存地址。

+ 缺页中断：如果内存块不再内存中，则会发生中断，中断处理程序处理中断，缺页的进程阻塞，调页完成后唤醒
  + 如果内存中有空闲块，则为进程分配一个空闲块
  + 如果村内中没有空闲块，通过页面置换算法选择一个页面淘汰，若被淘汰的页面内存期间被修改过，则要写回外存

#### 页面置换

+ 指标：追求更少的缺页率
  + 缺页率：缺页的次数除以总访问次数
+ 区分缺页中断和页面置换

1. 最佳置换算法OPT, Optimal：每次选择淘汰的页面将是以后永远不再使用的，或者是最长时间内不再访问的页面，保证最低的缺页率
   > 但实际使用中不可能“预知未来”（该算法指标最好但是无法实现）

2. 先进先出置换算法FIFO：每次选择淘汰的页面是最早进入内存的页面，有Belady异常
   > Belady异常：当为进程分配的物理块数增大时，缺页次数不减反增的异常现象

3. 最近最久未使用置换算法LRU，least recently used：每次淘汰的页面是最近最久未使用的页面。在页表中的访问字段项中记录该页面上次被访问以来所经历的时间。该算法指标好，但是需要对应硬件实现、开销大

4. 最近未用算法NRU，Not Recently useed/时钟置换算法Clock：
   + 基础款：为每个页面设置一个访问位，1表示最近访问过，否则为0表示最近没有访问过，内存中的页面组成循环队列，被访问的页面将访问位设置为1，如果需要淘汰页面，循环访问，遇到访问位为0则丢弃，遇到访问位为1则置为0（做多两次循环就能成功淘汰）。
   + 改进款：没有修改的页面不用写回外存，如果需要淘汰可以优先淘汰这样的页面减少消耗  
     设置访问位和修改位：
     1. 一轮扫描，找访问位为0且没有修改的，同时将访问位为1的置为0
     2. 二轮扫描，找访问位为0且没有修改的，（经过第一轮各个页面访问位已经置为0）
     3. 三轮扫描，找访问位为0且修改的，（二轮扫面没有成功说明都修改过了）

#### 页面分配
驻留集：指请求分页存储管人力中给进程分配的物理块的集合	

+ 太小，缺页频繁
+ 太大，并发度下降，

+ 是否可变：
  + 固定分配：为每个进程分配一个固定，
  + 可变分配

+ 置换策略
  + 局部置换：只能选择自己的物理块进行转换
  + 全局置换：可以将系统保留的空闲物理块分配缺页进程，其他进程也可以
---
+ 页面分配、置换策略
  + 固定分配局部置换：
  + 可变分配全局置换：先补充内存，不行再还页面
    + 换未锁定的页面
  + 可变分配局部置换：可能减少
---
何时调入页面？
1. 预调页策略：根据局部性原理，一次调入一堆页面，这样次数少，但是如果没有猜对（50%），就啦了，所以一般主要用于进程的首次调入
---
+ 外存中：
  + 对换区：读写速度更快，采用连续分配方式
  + 文件区：读写速度更慢，采用离散分配方式
  1. 如果对换区足够，可以通过内存——对换区——文件区的方式
  2. 不足够，就是内存——文件去了
  3. Unix：文件去->内存->对换区
+ 抖动/颠簸现象：刚刚换出的页面马上又要换入内存，刚换入的又要换出，
+ 主要是进程频繁访问的页面数高于可用物理块
+ 工作集：某段时间间隔里，进程实际访问页面的集合
  > 驻留集指请求分页存储管理中给进程分配的内存块的集合

  抖动的评价指标就是：驻留集大小不能小于工作集大小


当提到"buddy"和"slab"时，这通常指的是内存管理中的两种分配算法，用于操作和管理计算机系统的内存资源。下面是关于这两种算法的简要介绍以及一些建议的学习资源：

Buddy（伙伴）分配算法：Buddy分配算法是一种常见的内存分配算法，用于动态分配内存块。它将可用内存划分为大小相等的块，并使用二叉树来跟踪和管理这些块。当请求分配内存时，Buddy算法会将最接近所需大小的可用内存块分配给请求者，而其他较大的块则会被分割成较小的块。这种算法的优点是能够有效地利用内存，但可能会导致内存碎片化。

Slab（页面缓存）分配算法：Slab分配算法是一种内存管理算法，用于高速缓存中的对象分配。它通过将内存预先分配为固定大小的缓存对象块（slab）来提高内存分配的效率。当需要分配对象时，Slab算法会从已分配的slab中选择一个，并将对象分配给请求者，而不需要进行额外的内存分配操作。这种算法的优点是提高了内存分配速度和效率，但可能会导致内存浪费。

以下是一些关于buddy和slab的学习资源，这些资源包括文章、视频和文档，可以帮助您更深入地了解它们：

文章：

"Understanding the Linux Kernel" by Daniel P. Bovet and Marco Cesati (Chapter 8: Memory Management) - 这本书详细介绍了Linux内核的各个方面，包括内存管理和相关算法。
"Introduction to the Slab Allocator" by Linux Weekly News - 这篇文章解释了Linux内核中的Slab分配器的工作原理和实现细节。
视频：

"Memory Management Part 2: Buddy Allocator" by CrashCourse - 这个视频在一个系列中介绍了内存管理的不同方面，其中包括Buddy分配算法的解释和示例。
"Linux Memory Management" by The Linux Foundation - 这个视频课程深入讲解了Linux内核中的内存管理，包括Buddy和Slab算法的细节。
文档：

"Understanding the Linux Virtual Memory Manager" by Mel Gorman - 这份文档提供了关于Linux内存管理的详细解释，包括Buddy和Slab算法的实现和优化。
"The Slab Allocator: An Object-Caching Kernel Memory Allocator" by Jeff Bonwick - 这篇论文详细介绍了Slab分配器的设计和实现原理。
请注意，这些资源可能需要一定的计算机系统和操作系统知识作为先决条件。如果您对这些主题感到陌生，可能需要先了解相关的基础知识。