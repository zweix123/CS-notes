
考虑这样的场景, 我们有批量的参数需要去查询查询,
假如是简单的串行执行, 肯定是划不来的, IO密集型的场景中我们肯定有大量的时间在等待.
所以需要异步, 但是一口气将请求全部都发出去也有新的问题; 主要发生在参数的批数过多时,
1. 我们在短时间内创造了大量的协程
2. 对下游的访问量是突增的, 可能造成被限流, 导致很多可以正常访问得到结果的请求失败.
一个可能可以的做法是, 首先将我们批量的参数进行分片, 每个片包含多个参数, 每个片之间是串行的, 在每个片内部则并行执行.

这样就兼顾了串行和并行的问题.

扩展这个场景, 假如下游的接口支持批量查询呢?
可以直接将我们的所有参数都一口气发送出去么? 很有可能不行, 因为对于每个参数进行处理的时间是客观存在的, 当多个参数一起请求时, 由于长尾效应, 可能造成整个请求超时.
那么可以按上面的将请求分片然后片与片之间串行, 每个片直接批量查询么?有两个问题
1. 可能原本的问题依然没有解决, 因为长尾效应是客观存在的, 只是批量查询中的参数数量越小, 其出现的可能越小, 所以这里要结合下游接口方的建议.
2. 我们最初为什么不使用简单的异步呢? 协程和访问的突增, 这里只有串行没有并行, 并且显然有并行的余地.
扩展最初的做法, 分片之后再分片, 大片与大片直接是串行的, 大片内部的小片是通过批量查询的接口并行的, 且这里的小片大小是结合下游避免长尾效应的建议值的, 小片个数是下游设置的限流值的.

这里是一种函数式表述
```go
Flatten(
    MapSeries(
        Chunk(input, big_chunk_size) -> []big_chunk,
        Flatten(
            MapParallel(
                Chunk(big_chunk, small_chunk_size) -> []small_chunk,  // 当下游不支持批量查询时, 这里的small_chunk_size相当于1
                F(small_chunk),
            ),
        ),
    ),
)
// Flatten是Chunk的逆操作, 相当于
/*
Reduce(
    collection,
    func(agg []T, item Slice, _ int) []T {
        return append(agg, item...)
    },
    []T{},
)
*/
```

## 关于“片”的概念

首先目前的设计是希望兼容下游接口的不同形态（单参数请求或者支持批量请求）。
无论是什么情况，都有“大片”和“小片”的概念，这里的每个小片就相当于一次请求的参数，假如下游只支持单参数请求，则这里的小片大小只能是1，否则则可以根据下游建议调整。

## 最终的方案

这里的大片间串行，小片间并行是为了解决协程数和访问量的徒增，其实有一个更好的解法——协程池。
我们只需要构造任务，具体的任务的调度由池内完成，而协程的数量也决定的并发量。

# 协程池库
> 最好还符合当前场景

