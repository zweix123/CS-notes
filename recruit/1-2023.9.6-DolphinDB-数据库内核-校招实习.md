效率真心高呀，神航内推完HR小姐姐就来了。

## 9.6-HR约笔试 | 9.7-笔试

询问HR得知不能公开笔试形式和内容。全是算法，挺有意思的。

<!--

```cpp
/*
ddb 2023 秋招实习 笔试 Q1
公司每天会有很多新的任务. 在接下来的n天, 有m个任务需要处理.
各个任务都有截至日期d[i], 任务收益为g[i],
如果没有在截至日期d[i]之前完成则无法获得收益, 但也不会有损失.
在第d[i]天完成任务也可以得到收益.
公司现在有r名员工. 最近大家都想放年假,
所以每个人只想就从第l[i]天工作到第r[i]天(包括第r[i]天), 然后就出去玩了.
每个人处理任务的能力也不同,
处理能力为w[i],表示在这几天的工作中一共能处理w[i]项任务量.
现在想让你帮我们分配一下任务, 使得接下来的n天总利润最大.
这里n, m, r的值域是[1, 2e5], 其他的合法但未说明限制
*/

#include <algorithm>
#include <cassert>
#include <cstdio>
#include <iostream>
#include <queue>
#include <vector>

using ill = long long;

const int N = 1e5 + 7;

int n, m, r;
struct Struct {
    int d;
    ill g;
    bool operator<(const Struct &other) { return d < other.d; }
};
Struct task[N];
Struct in[N], out[N];

//>3 5 2
//>2 3
//>1 10
//>2 10
//>3 2
//>3 10
//>1 3 2
//>1 23
//<33

int main() {
    scanf("%d%d%d", &n, &m, &r);
    for (int i = 1; i <= m; ++i) { scanf("%d%lld", &task[i].d, &task[i].g); }
    for (int i = 1; i <= r; ++i) {
        int l, r;
        ill g;
        scanf("%d%d%lld", &l, &r, &g);
        in[i].d = l;
        out[i].d = r + 1;
        in[i].g = out[i].g = g;
    }
    std::sort(task + 1, task + m + 1);
    std::sort(in + 1, in + r + 1);
    std::sort(out + 1, out + r + 1);

    std::priority_queue<int, std::vector<int>, std::greater<int>> heap;

    ill ans = 0;
    ill in_sum = 0, out_sum = 0;
    int in_cnt = 0, out_cnt = 0;

    for (int i = 1; i <= m; ++i) {
        while (in_cnt + 1 <= r && task[i].d >= in[in_cnt + 1].d) {
            ++in_cnt;
            in_sum += in[in_cnt].g;
        }
        while (out_cnt + 1 <= r && task[i].d >= out[out_cnt + 1].d) {
            ++out_cnt;
            out_sum += out[out_cnt].g;
        }
        if (in_sum <= (int)heap.size()) { // HACK
            // if (in_sum - out_sum - (int)heap.size() <= 0) {
            if (heap.empty()) continue;
            assert(!heap.empty());
            if (task[i].g > heap.top()) {
                ans -= heap.top();
                heap.pop();
                heap.push(task[i].g);
                ans += task[i].g;
            }
        } else {
            heap.push(task[i].g);
            ans += task[i].g;
        }
    }
    printf("%lld\n", ans);

    return 0;
}
```

```cpp
/*
ddb 2023 秋招实习 笔试 Q2
现在超级计算机SSoM需要顺序执行n个任务. 这些任务有读写和计算两个部分,
第i个任务需要读写r[i]个单位的数据, 并计算c[i]个单位的数据.
SSoM有两种状态:计算状态和读写状态.
如果SSoM的处理能力为t,
在计算状态下, 处理第i个任务耗时为std::ceil(r[i] / (2.0 * t)) + std::ceil(r[i] /
(1.0 * t)); 在读写状态下, 处理第i个任务耗时为std::ceil(r[i] / (1.0 * t)) +
std::ceil(r[i] / (2.0 * t)); 因为频繁切换会减少机器寿命, 所以最多只能切换m次.
SSoM有多个型号, 每个型号的处理能力不同. 为找到适合的型号处理任务,
现在想知道t最小为多大的正整数才能在时间T之内完成所有任务. SSoM初始为计算状态. n,
m <= 1e3, T <= 1e6, r[i], c[i] > 0
*/
#include <cassert>
#include <cmath>
#include <cstdio>
#include <cstring>
#include <iostream>

const int N = 1e3 + 7;
const int T_MAXN = 1e6 + 7;
const int INF = 1e9 + 7;

int n, m, T;
int reads[N], cals[N];

int f[N][N]; // f[i][j]表示处理第i个任务时, 状态变换j次的最少用时。
// 相邻之间的转移，只需要考虑(i - 1, j - 1)和(i - 1, j)即可
// 因为多余的变换不会更优,
// 而状态可以直接从变换次数中拿到, 不需要额外的维度
// 复杂度n放可以接受

int get(int index, int state, int mid) {
    if (state == 0) {
        return std::ceil(1.0 * reads[index] / (2.0 * mid))
               + std::ceil(1.0 * cals[index] / (mid));
    } else {
        assert(state == 1);
        return std::ceil(1.0 * reads[index] / (mid))
               + std::ceil(1.0 * cals[index] / (2.0 * mid));
    }
}

bool check(int mid) {
    memset(f, 0, sizeof(f));
    for (int j = 0; j <= m; ++j) f[1][j] = get(1, j & 1, mid);
    for (int i = 2; i <= n; ++i) f[i][0] = f[i - 1][0] + get(i, 0, mid);
    for (int i = 2; i <= n; ++i) {
        for (int j = 1; j <= m; ++j) {
            f[i][j] =
                std::min(f[i - 1][j - 1], f[i - 1][j]) + get(i, j & 1, mid);
        }
    }
    for (int j = m; j >= 0; --j)
        if (f[n][j] <= T) return true;
    return false;
}

//>6 2 20
//>1 1
//>2 3
//>2 2
//>4 3
//>1 4
//>7 2
//<2

int main() {
    scanf("%d%d%d", &n, &m, &T);
    for (int i = 1; i <= n; ++i) { scanf("%d%d", &reads[i], &cals[i]); }
    int l = 1, r = INF, ans = -1;
    while (l <= r) {
        int mid = (l + r) >> 1;
        if (check(mid)) {
            ans = mid;
            r = mid - 1;
        } else {
            l = mid + 1;
        }
    }
    printf("%d\n", ans);

    return 0;
}
```

```cpp
/*
ddb 2023 秋招实习 笔试 Q3
函数mrank在线地接收一个数字, 并返回其在所有已接收的数字中的排序.
每个元素的排序仅仅与其之前的元素相关, 与其之后的元素无关.
*/
#include <cassert>
#include <iostream>
#include <iterator>
#include <set>
#include <vector>

int mrank(int num) {
    static std::multiset<int> mrank_set;
    auto ans = std::distance(mrank_set.begin(), mrank_set.lower_bound(num));
    // 意义不大, 这样不如直接在set上遍历[捂脸]
    mrank_set.insert(num);
    return ans;
}

int main() {
    std::vector<int> arr = {1, 3, 2, 3, 4};
    std::vector<int> ans = {0, 1, 1, 2, 4};
    assert(arr.size() == ans.size());
    for (int i = 0; i < arr.size(); ++i) { assert(mrank(arr[i]) == ans[i]); }
    return 0;
}
```

```
**复杂度说明**

1. 任务分配: $O(n \times log n)$ 
2. 超级计算机: $O(n^2 \ log )$ (我这里二分的上限是`1e9`，所以这里的`log`本质是一个常量，但是时间复杂度里应该没有常量，所以只以单独`log`表示)
3. mrank: 函数`mrank`每次调用的时间复杂度是$O(n)$

**题目思路**

1. 任务分配

有一个和该题目很相似的题目，去掉多个时间段内能完成的任务数量的限制，每个单位时间固定完成一个任务，那道题是反悔贪心的模板题目。  
那么这个题目的主体就可以使用类似的形式，拿一个小根堆，从早到晚，尽量早的完成任务，放进堆中，如果出现时间不够的情况，就替换掉堆顶的任务（如果比它更优）因为出现冲突的任务可以在当前时间做，也一定可以在更早的时候做。  
而这里增加了不同时间段能做的任务的数量限制。我的代码可能会有锅，但是我测试了几个样例没有问题。

时间复杂度上面排序 $n log n$，扫描一遍线性，在扫描的过程中会修改堆，总复杂度也是 $O(n \times log n)$ 

由于题目中没有给出值域，这里尽量大的使用`long long`。

1. 超级计算机

首先肯定是二分答案，那么怎么判断一个`t`是合法的呢？

其实对于这种只能变换最多固定次数的形式也做有印象，应该是做过，但是这个找不到原题。而且这里的`n`的数据范围也是引导，总之就想注释里说的，使用二维数组`f`，这里`f[i][j]`表示从1到`j`中变换`j`次状态的最小时间。首先肯定是从相邻的之间推导，然后变换的次数超过1是没有意义的，因为时间和变换0或者1次的一样，而白白浪费了变换次数，所以相邻位的推导是常数的。

这样的话空间复杂度是 $n^2$ ，然后每个位置循环一遍，每个位置各个变换次数也处理一遍，时间复杂度也是 $n^2$ 。  
这里判断一次的时间复杂度，加上二分，题目没有给出上限，这里使用`1e9`作为`t`的上限。所以实际复杂度应该是  $O(n^2 \ log (1e9) )$

同样由于题目中没有给出值域，这里二分的上线使用`1e9`，整份代码的值域也在`int`范围内

3.mrank

看到题目下意识的想到了`set`的`lower_bound`，下意识的写完`std::distance(mrank_set.begin(), mrank_set.lower_bound(num))`，才意识到`std::distance`是线性的，这样`set`和二分的优势全无。仔细想象这个题目应该是实现红黑树的变种。但是我没有能力不依靠参考资料实现红黑树或者其他平衡树。
```

-->

## 9.22-一面

<!--~~ddb强度挺大呀，HR催了三次面试官大哥才看的我的笔试代码。~~-->

一个小时System拷打酣畅淋漓，面试官是秋招第二个按着简历一个一个问的，呜呜好感动。

+ 面试官设备出问题不能开摄像头，所以也没限制我是否开摄像头。
+ 询问是否可以录屏，同意并叮嘱不能传播，于是进一步问是否可以写面经，答复可以。
+ 自我介绍。

1. 你是怎么设计学习计划的，已经学了哪些，还计划学什么？
2. 解释器：
	+ 是课程作业还是什么课程？
3. Redis的Modern C++实现
	+ 哪里体现Modern？
		+ RAII管理资源，比如文件描述符和套接字。
		+ 标准库，`Optional`，并发相关。
		+ Redis的有序集使用侵入式数据结构实现，如果要Modern的话只能CTRP，这里本身就不好实现，而且对析构需要异步，所以目前只能说有方向，但是没有实现。
		+ 项目结构借鉴了CS144和CMU15445的CMakeLists.txt
	+ 你是具体是怎么实现的，比如网络模块和存储模块的实现，和真实的Redis有哪些异同。
		+ 网络通信：
			+ 对C风格系统调用接口的封装，不仅是调用的封装，还有其安全的管理，比如对文件描述符的获取和释放，套接字的抽象，对每个TCP链接的抽象，对于`poll`的异步IO的字节缓冲流的抽象封装。
		+ 存储部分：主要是各种数据结构的实现
			+ 有序集是能渐进调整的，基于拉链法的哈希表和二叉平衡树AVL树的使用侵入式数据结构技术的结合。
				+ Redis使用跳表。
			+ 有序链表实现定时器。
			+ 堆管理键的TLS
				+ 惰性删除和RAII的冲突（上面提到）
	+ 是单线程模型嘛？
		+ 在确定删除和进行删除之间有一个小异步。
4. 说说你对CS144的实现，从send，到另一端的receive，你的实现经过哪些网络层次，涉及哪些算法，或者说就是讲讲你的实现。
	+ CS144提供的基础设施：
		+ 之前讲的对C风格接口或者系统调用的封装。
		+ 数据类
	+ 字节流：二倍大小循环队列实现字节流缓冲。
	+ 重排器：使用链表维护不重叠区间。
	+ TCP的收发两端就是按照接口普通的模拟
	+ 我做的2023没有对TCP状态机的实现
	+ 其他就是零碎的比如将TCP数据流到IP数据包的包装和拆包，从IP地址到MAC的相互转换。

	>这里我还忘了，共享屏幕看的笔记才想起来的。

	性能测试使用的是官方提供还是自己的方法进行测试？
 
5. 讲一讲你量化交易系统中的优化部分。
	+ 调整系统调用代码的分布
	+ 对不同的字符串到枚举的缓冲
	+ 去掉不必要的安全性检测。
 
6. xv6中也提到对系统调用的优化，都指的哪里？
	+ 共享页
	+ COW

	+ 时间相关系统调用：
		+ 你在Redis中应该也有时间相关的需求，包括精度之类的，你是怎么做的？
			仅仅是获取当前时间，精度是毫秒，从C++标准库拿到。

		+ 你对操作系统关于获取时间的相关服务和接口有哪些了解？

		如果要测试性能，获取时间本身操作的开销就有影响，而且跟时间相关的系统调用，Linux有很多对其的优化，和你在简历上说的很类似。

+ 复盘：
	+ Reference：[How Time Work](https://hoswey.github.io/2020/08/25/how-time-work/)
	+ 系统调用`gettimeofday`
		```c
		#include <sys/time.h>
		int gettimeofday(struct timeval *tv, struct timezone *tz);
		```
		现代操作系统主板上会有一个Real Time Clock，记录当前时间，通过主板电池CMOS Battery维持，电池没电则出问题  
		机器启动会读取这里的值保存到Kernel中，然后再有一个寄存器TSC，保存的是CPU的cycle（频率的倒数）个数，然后计算当前时间

		这里肯定会进入内核态的。

	+ `gettimeofday`调用系统调用`clock_gettime`

7. 你在分析量化交易系统的性能瓶颈时使用火焰图，但是并没有找到性能瓶颈，你觉得这是为什么？  
	你当时的火焰图是用什么生成的？  
	它采集和profile的原理是什么？不是获取运行时栈的信息，是采样时怎么知道每个段的耗时，这个在C++中是怎么样的？

+ 首先强调两个性质和三个概念：
	+ 有序性：对一个变量的读写是原子的
	+ 可见性：对一个变量的写完成后立刻被其他线程可见

	为什么会出现上面的问题？我目前的理解是现代体系结构中，内存中的信息是读取到寄存器中，然后进行计算，即分成读、算、写三步，如果出现这三步没有完成即出现了上下文切换则出现错误。同时现在CPU通常有缓存，即一个线程完成对内存的写后，未必立刻就写回到对应的内存中，此时其他指令对该位置的读则出现错误。
	>还有其他各种乱序执行、流水线、分支预测、多级缓存。

	+ 内存屏障Memory Barrier：保证以上两个性质的实现的软硬件指令，是体系结构层次
	+ 内存模型Memory Model：即编程语言为实现以上两个性质的对内存屏障的语义定义和使用规则
	+ 内存序Memory Order：我理解是内存模型语境下有序性的名称，通常有顺序一致性（Sequential Consistency）、释放-获取序（Release-Acquire Ordering）、强制排序（Total Store Ordering），强度一次递减。
		>但是我并不能直觉的区分这三者区别
 
+ Q1：
	```cpp
	struct SpinLock {
		void lock() {
			while (locked) {
				// do nothing
			}
			locked = true;
		}
		void unlock() {
			locked = false;
		}
		bool locked = false;
	};
	```

	上面自旋锁的实现有什么问题？

	+ 首先是竟态问题，这里`locked`变量的读写可能会出现竟态。

	+ 我在回答的时候还答错一个，即这里自旋锁是空转的，白白浪费了CPU。实际上，这就是自旋锁的性质，它就是空转CPU的，它带来的问题应该通过程序员的最佳实践解决。

	比如这样实现：
	```cpp
	struct SpinLock {
	    std::atomic_flag locked = ATOMIC_FLAG_INIT;
		void lock() {
			while (locked.test_and_set(std::memory_order_acquire)) {}
		}
		void unlock() {
			locked.clear(std::memory_order_release);
		}
	};
	```

	或者hiki佬的实现
	```cpp
	class SpinLock {
		std::atomic<bool> flag{false};
	public:
		void lock() {
			while (flag.exchange(true, std::memory_order_acquire));
		}
		void unlock() {
			flag.store(false, std::memory_order_release);
		}
	};
	```

	所以用什么内存序？

	即上面的代码实现

	+ 这里即使用释放-获取序：
		+ acquire保证在该原子操作完成之前，所以对共享数据的加载都不会被重排到该原子操作之后
		+ release保证在该原子操作完成之后，所有对共享数据的加载都不会被重拍到该原子操作之前

+ Q2：
	```cpp
	struct MultiLockGuard {
		MultiLockGuard(std::initialize_list<SpinLock*> ls) : locks(ls) {
			for (auto l: locks) l->lock;
		}
		~MultiLockGuard() {
			for (auto l: locks) {
				l->unlock();
			}
		}
		std::vector<SpinLock*> locks;
	};
	```

	上面代码有什么问题？

	+ 死锁：
		+ 一方面不能保证用户传入的锁列表是正确的，比如把一个锁两次放进list中，那就死锁了，甚至用户可以直接传入空指针，所以应该要做检测和去重。
		+ 另外就是放的顺序可能导致死锁，比如一个的锁列表是`a, b`，另一个是`b, a`，两个线程同时拿到了自己列表的第一个锁，然后就死锁了。
		+ 还有在hiki佬指出的拿放锁的最佳实践问题：解锁顺序一般与枷锁顺序相反。因为一般来说越后面lock的锁，它的scope应该越小，也应该越早释放，而且正序解锁还有一个线程频繁切换的问题。即如果有两个多个锁的锁列表是一样的，如果正序释放，一个线程释放一个锁，另一个线程就抢掉了这个锁，而之后的锁不能立刻抢到，还得等释放的线程接着释放。

+ Q3：
	```cpp
	struct ThreadPool {
		ThreadPool(std::size_t num) {
			for (decltype(num) i = 0; i < num; ++ i) {
				workers.push_back(std::thread(poll, this));
			}
		}
		~ThreadPool() {
			stop.store(true, std::memory_order_seq_cst);
		}
		void push(std::packaged_task<int()>&& task) {
			taskqueue.push(std::move(task));
		}
		static void poll(ThreadPool* pool) {
			while (!poll->stop.load(std::memory_order_seq_cst)) {
				auto task = std::move(pool->taskqueue.front());
				pool->taskqueue.pop();
				task();
			}
		}
		std::atomic<bool> stop;
		std::vector<std::thread> workers;
		std::queue<std::package_task<int()>> taskqueue;
	};
	```

	+ 这里的
		```cpp
		stop.store(true, std::memory_order_seq_cst)
		stop.load(std::memory_order_seq_cst)
		```

		即顺序一致的内存序

	上面代码有什么正确性问题和性能问题
	>这里对push和poll两个操作没有加锁，先忽略。
	
	+ 这个`push_back(this)`这个事儿就得掂量掂量，比如用户使用智能指针维护线程池，而这个poll是静态的，很有可能poll拿到的ThreadPool的指针已经被其他智能指针释放了。有标准库解决这个问题，即公有继承` std::enable_shared_from_this<T>`，这也是一个CRTP，这个类有成员函数`shared_from_this()`解决这个问题。
	+ 性能问题：初始化那里，通过`resize`初始化。

	你写多线程写的多吗？比如有个接口叫做`join`知道么？它是否可以解决这个线程池的一些问题

	+ 在这个线程池的析构里，仅仅通过一个原子变量去表示该线程池是否有效，在此之后确实不会再有新的线程开始，但是之前的线程可能仍然在跑，这时它们的语义就是奇怪的，很反直觉。所以这里要`join`下，即在线程池析构前，保证为之前维护的线程都已经运行完毕。

	好，你上面提到传递`this`的问题，即使使用智能指针维护，但是这里把`this`指针给到`poll`，然后这个`poll`本身还在线程池中，那么这里可不可能出现循环引用的问题呢？

	确实会的，如果使用智能指针维护了，比如外界使用智能指针维护这个线程池，然后线程池中，`std::vector`的每个成员都维护一个`poll`的线程，而线程中每个实例也都拿着这个线程池的智能指针。那么这会发生什么呢？即只有当线程池析构的时候，才会析构这里的`std::vector`，它们里面的线程池本身的智能指针才会减少对应的引用计数。但是在析构前引用计数永远不会减少到0，永远不会析构。循环引用了。

	+ 对这里的队列的使用没有加锁。

	还有没有性能问题，比如如果构造函数参数`num`很大，每个线程的`poll`运行都会有一个锁的竞争，这里竞争可能很大，怎么办？你在做xv6时有没有相关问题，比如如何降低对锁的竞争？我印象里有就是将其拆分成多个锁，这样每个锁的竞争更少。
	>这里我依然不能直观的理解。

	在Usamoi佬的提示下，可以使用**work-steal**解决：保留线程池的FIFO队列，为每个worker都提供一个双端队列，所有对线程池的Push都是放进FIFO队列，然后有单独的线程调度这个FIFO讲其中的任务给到各个worker的队列中，每个worker只从自己的队列拿任务，这样就降低了锁竞争，本质还是锁拆分。

	![](https://cdn.jsdelivr.net/gh/zweix123/CS-notes@master/resource/recruit/usamoi-in-work-steal.png)

+  Q4：
	```cpp
	int doFib(ThreadPool& p, int n) {
		if (n < 2) {
			return n;
		} else {
			std::packaged_task<int()> taskx([&]{doFib(p, n - 1); }); // wrap the function
			std::future<int> fx = taskx.get_future();  // get a future
			p.push(std::move(taskx));
			
			std::packaged_task<int()> tasky([&]{doFib(p, n - 2); }); // wrap the function
			std::future<int> fy = taskx.get_future();  // get a future
			p.push(std::move(tasky));

			fx.wait();
			fy.wait();

			int x, y;
			x = fx.get();
			y = fy.get();
			return x + y;

		}
	}

	int fib(int n) {
		ThreadPool p(100);
		return doFib(p, n);
	}
	```

	上面哪里会死锁？

	这里的`wait`和`get`会等待子线程，但是如果线程池容量比较小，大量的线程的都会等待它的子结点的计算，但是线程池已经占满了，后面的几点不会被计算，死锁。

	怎么解决？

	给每个线程提供主动放权的操作。
	>我以为只能在C++标准库上做文章，但是面试官的意思是需要编译器或者操作系统提供支持。
 
	相当于要提供一个接口类似有栈协程的主动放权。

	那我看你在xv6里也有一个用户级线程的实现
	+ 主要有两个：
		+ 一个是提供系统调用允许用户设置几个CPU后周期对某个线程进行中断
		+ 另一个是用户级线程切换，即编写汇编代码，在不进入内核态的情况下保存和切换寄存器上下文。

+ 反问：
	+ 面评

>自我感觉回答的还是比较差劲的，感谢面试官给了通过。


## 10.10-二面 | 10.12-挂

不允许录屏、不允许传播面经。

实际上只有一个内容，开放寻址法一次探测哈希表，估计后面还想进一步问来着。但是这里确实懵住了，面试时间短就只问了这一个。

[这是一个我面试后的实现](https://github.com/zweix123/code-examples/blob/master/HashTable/OpenAddressing.h)
