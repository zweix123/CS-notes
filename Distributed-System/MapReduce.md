## 论文精读

>   论文在MIT6.824官网给出链接，同时网上有诸多论文翻译作为辅助资料

论文写的相当清楚，强烈建议精读论文，下面的笔记主要是逻辑的梳理和理解以及在lab中实现的注解
>   zweix读论文的一些心得
>   +   区分`worker`和`master`、`task`和`job`的概念（主要在实现部分），worker是系统中的一个物理机器，master是特殊的worker，每个work（无论是Map worker和Reduce worker）都会读入一个文件并处理这个文件，这个过程是一个task，一个worker上可能运行多个Map或Reduce函数，worker处理这些文件并分给这些函数，一个运行的函数就是一个job

+   意义：Google面临着对大量数据的运算，只有分布式的部署才能在可接受的时间范围内解决，但分布式是一个复杂问题，工程师必须具备分布式开发的能力，同时必须要面对分布式中诸如并行运算、容错、本地优化和负载均衡等等问题。Google希望将这些细节封装起来，使工程师将注意力集中在要解决的问题上，甚至不具备分布式开发的能力也能充分使用分布式的性能。
    >   这里的实现是受限制的restricted的，需要工程师将原本的算法转换成一个符合*mapreduce specification*的实现

+   启发：启发于函数式编程语言的*Map*和*Reduce*原语primitives，有些问题可以转换成这样的算法模型（或者该模型的组合）：这个算法模型由多个Map函数和多个Reduce函数组成
    ```
    map    (k1. v1)       -> list(k2, v2)
    reduce (k2, list(v2)) -> list(v2)
    ```
    +   一个map函数通常读入一个文件，比如key是文件名、value是文件内容，然后输出一些键值对的列表，这些键值对被称为“中间键值对”
    +   每个reduce函数从各个Map输出的中间键值对中选择某一个键的所有值进行计算
    
+   评估：
    +   可行性：上面说“某些问题”，在论文中阐述了较多的案例。
        >   在上课的学生提问中，老师也提到设计这样的算法其实也不简单
    +   可扩展性：上面我们发现map的处理是“上下文无关”的，也就是说如果map内的算法是“确定的”，那么一个任务拆分成多个map去处理和单个map处理的结果应该是等价的，同时每个reduce只关注每个中间键值对的某个键，如果map们的输出是确定的，那么reduce接受的数据也是确定的。  
        即我们可以通过增加机器来更快的完成任务
        >   关于“确定性”的问题在论文中也讨论了如果map和reduce是不确定的情况

那么MapReduce框架的用户只需要考虑如果将问题转换成上面的程序模型，即可利用框架实现分布式的部署，而用户不用考虑分布式所面临的并行运算、容错、本地优化和负载均衡等等问题。

+   实现：MapReduce有多种实现，论文给出了一种实现，并详细给出流程、数据结构、容错和其他细节。  
    下面会随着lab的进行做进一步说明
    +   容错

+   效果：
    +   程序的设计和实现更加容易，且代码量急剧减少
    +   将问题的处理和分布式的部署解耦，在项目修改时快很多
    +   程序运行更流程且很容易扩展

## 实验编码